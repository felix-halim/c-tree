<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<style type="text/css">
.axis path,
.axis line {
  fill: none;
  stroke: black;
}
.line {
  fill: none;
  stroke: steelblue;
  stroke-width: 1.5px;
}
</style>
<script src="d3.v3.min.js"></script>
<script src="data.js?8"></script>
<script>
data = d3.csv.parse(data);
</script>
<script src="linechart.js?8"></script>
</head>

<body onload="renderLinecharts()">

<p>All experiments uses N = 10^8 random sparse 32 bit integer.<br>
The queries are random point queries.<br>
The updates are random point updates in the same 32 bit integer domain.<br>
</p>

<h2>Racing for Queries</h2>

<p>Given a certain amount of time, how many queries can an algorithm answers?<br>
The setup is: insert 10^8 random integers and perform 10^9 point queries.
</p>

<div class="chart" style="float:left; display: inline-block">{
  width: 450, height: 225,
  yAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  xAxis: { label: 'Timeline (seconds)', attr: 'total_time', scale: 'log', domain: [0.4, 3000], format: 'd', ticks: [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 2000, 3000], margin: 40 },
  legend: {
    'sort' : { x: 250, y: 120 },
    'art_best_eager' : { x: 250, y: 80 },
    'btree_google' : { x: 250, y: 100 },
    'mdd1r' : { x: 70, y: 150 },
    'crack' : { x: 30, y: 70 },
    'comb' : { x: 30, y: 90 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',   values: ['Random'] },
    { attr: 'Q',   values: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ] },
    { attr: 'algorithm',         values: ['sort', 'crack', 'comb', 'mdd1r', 'art_best_eager', 'btree_google'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="float:left; display: inline-block">{
  width: 450, height: 225,
  yAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  xAxis: { label: 'Timeline (seconds)', attr: 'total_time', scale: 'log', domain: [0.4, 400], format: 'd', ticks: [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 100, 200, 300, 400], margin: 40 },
  legend: {
    'sort' : { x: 185, y: 95 },
    'art_best_eager' : { x: 110, y: 140 },
    'btree_google' : { x: 275, y: 80 },
    'mdd1r' : { x: 90, y: 70 },
    'comb' : { x: 30, y: 30 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',   values: ['SeqOver'] },
    { attr: 'Q',   values: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ] },
    { attr: 'algorithm',         values: ['sort', 'comb', 'mdd1r', 'art_best_eager', 'btree_google'] },
  ]), 'algorithm'),
}</div>

<div style="display:none">
<br><br>
<input type="checkbox"> BTree (Google)<br>
<input type="checkbox"> CTree 32<br>
<input type="checkbox"> CTree 1024<br>
<input type="checkbox"> CTree 4096<br>
<input type="checkbox"> CTree Eager (like bulk insert BTree)<br>
<input type="checkbox"> Crack<br>
<input type="checkbox"> COMB<br>
<input type="checkbox"> Sort<br>
</div>

<p style="clear:both">
Left figure is random query workload. It is the worst for COMB/Crack.<br>
Right figure is sequential workload.<br>
It only touches X fraction of a the data domain where X is the fraction of the query sequence.<br>
That is, at 1M queries, the queries touches 0.1% of the data domain.<br>


<!-- Cracking ART (ARTC) answered 10M queries during the first 30 seconds.<br>
ART starts answering the first query after 29.3 seconds.<br>
BTree (BT) starts answering the first query after 54.5 seconds.<br>
In the end Cracking ART and ART finishes the 10^9 queries almost together.<br>
Cracking BTree (BTC) has similar performance with Cracking ART and thus omitted in the graph to reduce clutter.
 --><br>

<div class="chart" style="float:left; display: inline-block">{
  width: 450, height: 225,
  yAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  xAxis: { label: 'Timeline (seconds)', attr: 'total_time', scale: 'log', domain: [0.4, 400], format: 'd', ticks: [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 100, 200, 300, 400], margin: 40 },
  legend: {
    'combt2048' : { x: 200, y: 110 },
    'comb' : { x: 200, y: 90 },
    'ctree_32_64' : { x: 200, y: 130 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',   values: ['Random'] },
    { attr: 'Q',   values: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ] },
    { attr: 'algorithm',         values: ['combt2048', 'comb', 'ctree_32_64'] },
  ]), 'algorithm'),
}</div>

<br style="clear:both">

<p>Changing COMB's plain root array to (incremental) BTree helps but not that significant.<br>
Notice that CTree is bad for the first millions of queries because of bad Fusion efficiency.<br>
However it catches up later on. I'm puzzled why? My hunch is that small buckets is memory-friendly?<br>
This suggest that Transitive Indexing should be beneficial: Start with Large buckets, transition to smaller buckets eventually.<br>
I will implement the transitive indexing soon.


<p style="clear:both">

<h2>Read Only Queries</h2>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'NOUP: Ratio to Sort', attr: 'total_time', scale: 'log', domain: [0.05, 10], format: 'pow10', ticks: [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 40 },
  legend: {
    'sort' : { x: 50, y: 50 },
    'mdd1r' : { x: 250, y: 20 },
    'comb' : { x: 170, y: 110 },
    'comb_art' : { x: 170, y: 130 },
  },
  base: 'art_best_eager',
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'algorithm',         values: ['sort', 'comb', 'mdd1r', 'comb_art', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'NOUP: Ratio to Sort', attr: 'total_time', scale: 'log', domain: [0.05, 10], format: 'pow10', ticks: [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 40 },
  legend: {
    'sort' : { x: 50, y: 50 },
    'mdd1r' : { x: 250, y: 20 },
    'ctree_32_64' : { x: 30, y: 85 },
    'ctree_32_1024' : { x: 120, y: 110 },
  },
  base: 'art_best_eager',
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'algorithm',         values: ['sort', 'mdd1r', 'ctree_32_64', 'ctree_32_4096', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'NOUP: Ratio to Sort', attr: 'total_time', scale: 'log', domain: [0.05, 10], format: 'pow10', ticks: [0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 40 },
  legend: {
    'sort' : { x: 50, y: 50 },
    'art_best' : { x: 70, y: 125 },
    'art_best_eager' : { x: 250, y: 100 },
    'ctree_32_64' : { x: 30, y: 85 },
  },
  base: 'art_best_eager',
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'algorithm',         values: ['sort', 'art_best_eager', 'art_best', 'ctree_32_64'] },
  ]), 'algorithm'),
}</div>


<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'NOUP: Ratio to COMB', attr: 'total_time', scale: 'log', domain: [0.7, 5], format: 'pow10', ticks: [0.7, 0.8, 0.9, 1, 2, 3, 4, 5], margin: 40 },
  legend: {
    'mdd1r' : { x: 260, y: 50 },
    'ctree_32_64' : { x: 50, y: 40 },
    'ctree_32_1024' : { x: 120, y: 110 },
    'ctree_32_4096' : { x: 250, y: 105 },
    'comb' : { x: 55, y: 135 },
    'combt2048' : { x: 50, y: 20 },
  },
  base: 'comb',
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'algorithm',         values: ['comb', 'mdd1r', 'ctree_32_64', 'ctree_32_1024', 'ctree_32_4096', 'combt2048'] },
  ]), 'algorithm'),
}</div>

<!-- <div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'NOUP: Ratio to COMB', attr: 'total_time', scale: 'log', domain: [0.7, 5], format: 'pow10', ticks: [0.7, 0.8, 0.9, 1, 2, 3, 4, 5], margin: 40 },
  legend: {
    'combt512' : { x: 50, y: 40 },
    'comb' : { x: 55, y: 135 },
    'combt2048' : { x: 50, y: 20 },
  },
  base: 'comb',
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'algorithm',         values: ['comb', 'combt512', 'combt2048'] },
  ]), 'algorithm'),
}</div>
 -->
<p>Cumulative runtime compared to Sort under read only queries.
<ul>
<li>COMB is consistently faster than Crack on 10th+ queries.
<li>COMB is <b>never worse</b> than Sort on any number of queries.
<li>ART (with bulk insert) is faster than std::sort in initialization costs.
<li>ART is perforamnce is consistently fast O(K) per query.
<li>ART wins for large number of queries.
<li>Note for ART: if K is large, it may be a different story.
<li>Cracked ART (ARTC): has low initialization cost while preserve fast cumulative cost.
</ul>
</p>

<h3>Initialization Cost vs. Read only Query Cost</h3>

<svg id="fig1" width="275" height="200"></svg>
<svg id="fig2" width="250" height="200"></svg>
<svg id="fig3" width="250" height="200"></svg>
<svg id="fig4" width="250" height="200"></svg>
<svg id="fig41" width="250" height="200"></svg>

<p>Further breakdowns on the initialization cost (black bar) vs. query cost (gray bar) show that:<br>
Cracking ART inserts 10^8 random integers in 0.2 seconds and completed the first query in 0.6 second.<br>
Both ART and BTree requires 29.3 and 54.5 respectively to insert the 10^8 random integers.<br>
ARTC is 48x, 8x, 2x faster than ART on 1, 1K, 1M queries respectively and comparable on 1B queries.<br>
</p>


<h2>Low Frequency High Volume (LFHV) Updates</h2>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'log', domain: [0.3, 10], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'ctree_32_1024':  { x: 120, y: 20 },
    'crack':          { x: 120, y: 40 },
    'comb':           { x: 120, y: 60 },
    'ctree_32_64':    { x: 120, y: 80 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['crack', 'comb', 'ctree_32_64', 'ctree_32_1024', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'log', domain: [0.3, 10], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'comb':           { x: 240, y: 40 },
    'art_best':    { x: 40, y: 80 },
    'art_best_eager':  { x: 55, y: 20 },
    'ctree_32_64':  { x: 260, y: 85 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['comb', 'art_best', 'art_best_eager', 'ctree_32_64'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'log', domain: [0.3, 10], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'comb':           { x: 95, y: 20 },
    'comb1600':       { x: 95, y: 60 },
    'comb800':        { x: 95, y: 40 },
    'ctree_32_64':    { x: 95, y: 80 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['comb', 'ctree_32_64', 'comb800', 'comb1600', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'log', domain: [0.3, 10], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'combt8192':       { x: 95, y: 20 },
    'combt2048':       { x: 95, y: 40 },
    'combt512':       { x: 95, y: 60 },
    'ctree_32_64':    { x: 95, y: 80 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['ctree_32_64', 'combt512', 'combt2048', 'combt8192', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>


<p>Cumulative runtime compared to CTree under LFHV updates.
<ul>
<li>COMB is consistently faster than Crack on 10th+ queries.
<li>COMB does not eliminate the shuffling overhead, it reduces it down to O(sqrt(indexes)).
<li>CTree does not have shuffling overhead, it wins in the long run on heavy updates.
<li>CTree with 64 bucket size (CT64) is worse than COMB due inefficient Fusion.
<li>CTree with 1024 bucket size (CT1024) has better Fusion thus has similar performance to COMB for the first 10^5 queries<br>
but worse in the long run because of the high cost in updating large Bucket without (mini cracker) indexes.
<li>CTree can be modified to be "adaptive" in terms of bucket size (need more research).
<li>COMB800 can match CTree performance on updates due to smaller bucket size and less shuffling data in/out of buckets.
</ul>
</p>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'logx', domain: [0.1, 2.0], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'comb':            { x: 30, y: 15 },
    'comb800':         { x: 30, y: 30 },
    'ctree_32_64':     { x: 30, y: 45 },
    'combt512':        { x: 30, y: 75 },
    'comb_art':        { x: 30, y: 90 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['comb', 'ctree_32_64', 'comb800', 'comb_art', 'combt512', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'logx', domain: [0.1, 2.0], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'comb_art':        { x: 75, y: 30 },
    'ctree_32_64':     { x: 75, y: 45 },
    'art_best_eager':  { x: 75, y: 75 },
    'art_best':        { x: 75, y: 90 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['ctree_32_64', 'comb_art', 'art_best_eager', 'art_best'] },
  ]), 'algorithm'),
}</div>

<!-- <div class="chart" style="display: inline-block">{
  width: 600, height: 400,
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'logx', domain: [0.1, 2.0], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'comb800':         { x: 90, y: 20 },
    'ctree_32_64':     { x: 90, y: 40 },
    'comb_art':        { x: 90, y: 60 },
    'art_best_eager':  { x: 90, y: 100 },
    'combt512':        { x: 90, y: 120 },
    'combtr2':         { x: 90, y: 160 },
    'art_best':        { x: 90, y: 180 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['ctree_32_64', 'comb800', 'comb_art', 'art_best_eager', 'combt512', 'combtr2', 'art_best'] },
  ]), 'algorithm'),
}</div>
 -->
<div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e10], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9, 1e10 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'logx', domain: [0.03, 2.0], format: 'pow10', ticks: [0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4, 1.5, 6, 7, 8, 9, 10], margin: 30 },
  base: 'art_best_eager',
  legend: {
    'art_best_eager':  { x: 40, y: 20 },
    'comb_art':        { x: 40, y: 40 },
    'comb_art_ns':     { x: 40, y: 60 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9,1e10] },
    { attr: 'algorithm',         values: ['comb_art', 'comb_art_ns', 'art_best_eager'] },
  ]), 'algorithm'),
}</div>

<!-- <div class="chart" style="display: inline-block">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9 ], margin: 40 },
  yAxis: { label: 'LFHV: Ratio to ARTB', attr: 'total_time', scale: 'log', domain: [0.3, 2000], format: 'pow10', ticks: [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], margin: 30 },
  legend: {
    'comb800':       { x: 95, y: 40 },
    'ctree_32_64':    { x: 95, y: 80 },
    'comb_art':    { x: 95, y: 20 },
    'art_best':    { x: 95, y: 20 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['LFHV'] },
    { attr: 'query_workload',    values: ['Random'] },
    { attr: 'Q',                 values: [1,10,1e2,1e3,1e4,1e5,1e6,1e7,1e8,1e9] },
    { attr: 'algorithm',         values: ['ctree_32_64', 'comb800', 'comb_art', 'art_best', 'combt512'] },
  ]), 'algorithm'),
}</div>
 -->
<p>Replacing COMB's root array to (incremental) BTree does significantly helps under updates!<br>
The left figure is COMB6400 vs COMB-Tree2048 (superior).<br>
The right figure is for smaller bucket COMB800 vs COMB-Tree512 (superior).<br>
COMB800 suffers because it has too many entries in the root array while<br>
COMB-Tree512 handles the root array much better with (incremental) B-Tree.<br>

<p>Note that the COMB bucket is <b>NOT YET TRANSITIVE</b>!<br>
I believe it will be even better if it's transitive.


<h3>Initialization Cost vs. LFHV Query Cost</h3>

<svg id="fig5" width="275" height="200"></svg>
<svg id="fig6" width="250" height="200"></svg>
<svg id="fig7" width="250" height="200"></svg>
<svg id="fig8a" width="250" height="200"></svg>
<svg id="fig8b" width="250" height="200"></svg>

<p>Under low frequency high volume (LFHV) updates (i.e., update 1000 tuples every 1000 read queries),<br>
we can see the same trend that the cracked version of ART and BTree wins up till 100M LFHV queries.<br>
On one billion LFHV queries, however the lazy insert took noticeable overhead.<br>
This can be mitigated by doing eager insert after 100M queries.

<h2>Streaming Insert Interleaved with Random Count Queries</h2>
<div class="chart">{
width: 255,
xAxis: { label: 'Query Sequence', attr: 'Q', scale: 'log', domain: [0.5, 2e3], format: null, ticks: [1, 10, 1e2, 1e3], margin: 40 },
yAxis: { label: 'Cumulative Runtime', attr: 'total_time', scale: 'logx', domain: [-50, 500], format: 'pow10', ticks: [0, 100, 200, 300, 400, 500], margin: 40 },
legend: {
'crack_count' : { x: 50, y: 30 },
'comb_count' : { x: 50, y: 50 },
},
data: group(filter([
{ attr: 'update_workload', values: ['APPEND'] },
{ attr: 'query_workload', values: ['Random'] },
{ attr: 'selectivity', values: ['0.001000'] },
{ attr: 'algorithm', values: ['crack_count', 'comb_count'] },
]), 'algorithm'),
}</div>

<p>Insert 100K random tuples before each random COUNT(*) query with 0.1% selectivity.<br>
After 1000 inserts, the total number of tuples is 100M.<br>
Each count query requires the algo to iterate for each pieces to acquire it's size (including COMB).
<ul>
<li>Crack needs to shuffle in the pending insert for each query in range [a, b).
<li>If there is not enough room to shuffle in, then some elements is swapped with the pending insert (see MRI algorithm).
<li>This causes "trashing" effect where tuples constantly go back and forth to and from the array and the pending insert structure (AVL tree).
<li>COMB lazy insert appends or chain inserts to the correct bucket, no trashing.
<li>The result is that Crack gets worse rapidly as the size of the pending insert grows, and
<li>COMB stays resilient. It completes all 1000 inserts interleaved with a random count query in ~8 seconds while Crack in 445 seconds.
<li><b>Replacing AVL to ART</b> in Crack will not help Crack to become resilient in this case.
</ul>
</p>


<h2>Fusion Effectiveness on Different Bucket Sizes</h2>
<p>TODO
<ul>
</ul>
</p>

<!-- <div class="chart">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 2e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'Ratio to Sort', attr: 'total_time', scale: 'logx', domain: [0, 4], format: noFormat, ticks: [0, 1, 2, 3, 4], margin: 40 },
  base: 'art_best_eager',
  legend: {
    'sort' : { x: 100, y: 10 },
    'crack' : { x: 100, y: 30 },
    'comb' : { x: 100, y: 50 },
    'ctree_32_4096' : { x: 100, y: 70 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['NOUP'] },
    { attr: 'algorithm',         values: [
      'sort',
      'crack',
      'comb',
      'ctree_32_1024',
      'ctree_32_4096',
    ] },
  ]), 'algorithm'),
}</div>


<div class="chart">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 1e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'Cumulative Runtime', attr: 'total_time', scale: 'logx', domain: [0.1, 7], format: d3.format('s'), ticks: [0, 1, 2, 3, 4, 5, 6, 7], margin: 40 },
  base: 'art_best_eager',
  legend: {
    'ctree_32_64' : { x: 100, y: 10 },
    'crack' : { x: 100, y: 30 },
    'comb' : { x: 100, y: 50 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['QUEUE'] },
    { attr: 'algorithm',         values: [
      'crack',
      'comb',
      'ctree_32_64',
    ] },
  ]), 'algorithm'),
}</div>


<div class="chart">{
  xAxis: { label: 'Query Sequence',  attr: 'Q', scale: 'log', domain: [0.5, 1e9], format: ticksPow10, ticks: [1, 10, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7, 1e8, 1e9], margin: 40 },
  yAxis: { label: 'Cumulative Runtime', attr: 'total_time', scale: 'logx', domain: [0.1, 7], format: d3.format('s'), ticks: [0, 1, 2, 3, 4, 5, 6, 7], margin: 40 },
  base: 'art_best_eager',
  legend: {
    'ctree_32_64' : { x: 100, y: 10 },
    'crack' : { x: 100, y: 30 },
    'comb' : { x: 100, y: 50 },
    'ctree_32_4096' : { x: 100, y: 70 },
    'ctree_32_1024' : { x: 100, y: 70 },
  },
  data: group(filter([
    { attr: 'update_workload',   values: ['TRASH'] },
    { attr: 'algorithm',         values: [
      'crack',
      'comb',
      'ctree_32_64',
      'ctree_32_1024',
      'ctree_32_4096',
    ] },
  ]), 'algorithm'),
}</div>
 -->

<script>
barchart("#fig1", '(a) 1 Query', 'Total Time (s)', data, 'NOUP', '1', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_1024: 'CT', crack: 'CRK',
  comb: 'COMB',
  sort: 'SORT',
});

barchart("#fig2", '(b) 1K Queries', null, data, 'NOUP', '1000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_1024: 'CT', crack: 'CRK',
  comb: 'COMB',
  sort: 'SORT',
});

barchart("#fig3", '(c) 1M Queries', null, data, 'NOUP', '1000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_1024: 'CT', crack: 'CRK',
  comb: 'COMB',
  sort: 'SORT',
});

barchart("#fig4", '(d) 100M Queries', null, data, 'NOUP', '100000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_1024: 'CT', crack: 'CRK',
  comb: 'COMB',
  sort: 'SORT',
});

barchart("#fig41", '(e) 1B Queries', null, data, 'NOUP', '1000000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_1024: 'CT', crack: 'CRK',
  comb: 'COMB',
  sort: 'SORT',
});

barchart("#fig5", '(a) 1 Query', 'Total Time (s)', data, 'LFHV', '1', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_64: 'CT', crack: 'CRK', comb800: 'COMB',
});

barchart("#fig6", '(b) 1K Queries', null, data, 'LFHV', '1000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_64: 'CT', crack: 'CRK', comb800: 'COMB',
});

barchart("#fig7", '(c) 1M Queries', null, data, 'LFHV', '1000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_64: 'CT', crack: 'CRK', comb800: 'COMB',
});

barchart("#fig8a", '(d) 100M Queries', null, data, 'LFHV', '100000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_64: 'CT', crack: 'CRK', comb800: 'COMB',
});

barchart("#fig8b", '(e) 1B Queries', null, data, 'LFHV', '1000000000', {
  art_best_eager: 'ARTB', art_best: 'ARTC', btree_google: 'BT', ctree_eager: 'CTE', ctree_32_64: 'CT', crack: 'CRK', comb800: 'COMB',
});
</script>
</body>
</html>

